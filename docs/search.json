[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "this is project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nCarolyn Su\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Unstructured Data\n\n\n\n\n\n\n\n\n\nApr 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project 1/index.html",
    "href": "blog/project 1/index.html",
    "title": "Analyzing Unstructured Data",
    "section": "",
    "text": "Gathered Formula 1 data from Year 2000 to Year 2024 and cleaned the data"
  },
  {
    "objectID": "blog/project 1/index.html#section-1-data",
    "href": "blog/project 1/index.html#section-1-data",
    "title": "Analyzing Unstructured Data",
    "section": "",
    "text": "Gathered Formula 1 data from Year 2000 to Year 2024 and cleaned the data"
  },
  {
    "objectID": "blog/project 1/index.html#section-2-train-xgboost-model",
    "href": "blog/project 1/index.html#section-2-train-xgboost-model",
    "title": "Analyzing Unstructured Data",
    "section": "Section 2: Train XGBoost Model",
    "text": "Section 2: Train XGBoost Model\nUsed historical data to train an XGBoost Model\n\nimport numpy as np\nprint('123')\n\n123"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carolyn Su",
    "section": "",
    "text": "Hi there!\nMy name is Carolyn and I am an MSBA student at UC San Diego."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html",
    "href": "blog/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 paper published in The American Economic Review, economists Dean Karlan and John List conducted a large-scale natural field experiment to explore the effect of matching grants on charitable giving. The central question they addressed was whether changing the effective price of donating (i.e., increasing the impact of each donated dollar through matches) could influence individual giving behavior.\nThe study involved over 50,000 previous donors to a politically liberal nonprofit organization in the United States. Each donor received one of several versions of a fundraising letter via direct mail, a standard solicitation method used by the organization. The letters were identical in content—discussing an urgent national political issue—but varied in a few critical ways depending on the assigned experimental treatment.\nParticipants were randomly assigned to either:\n\nA control group that received a standard letter with no mention of a matching grant, or\nA treatment group that was informed of a matching offer funded by an anonymous donor.\n\nWithin the treatment group, further randomization occurred along three dimensions:\n\nMatch Ratio – Donors were told their contribution would be matched at a rate of $1:$1, $2:$1, or $3:$1.\nMaximum Match Size – The total matching fund was framed as being capped at $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amount – The solicitation letter used a donor-specific “example donation” set to be equal to, 1.25x, or 1.5x the donor’s highest previous contribution.\n\nThis design allowed the researchers to isolate not only the average effect of announcing a match but also to examine how donation behavior varied based on the size of the match ratio, the framing of the funding cap, and the suggested donation amount.\nThe results were both straightforward and surprising:\n\nAnnouncing the availability of a matching grant increased both response rate and total donations.\nHowever, increasing the match ratio beyond 1:1 did not produce additional gains—suggesting that donors responded to the presence of a match rather than its magnitude.\nInterestingly, the effect of the match offer was substantially stronger in red states (those that voted for Bush in 2004), suggesting political environment influences donor sensitivity.\n\nThis experiment not only contributed empirical evidence to the economics of charity—specifically the “demand side”—but also served as a real-world test of economic and behavioral theories such as impure altruism, warm-glow giving, and conditional cooperation. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#introduction",
    "href": "blog/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 paper published in The American Economic Review, economists Dean Karlan and John List conducted a large-scale natural field experiment to explore the effect of matching grants on charitable giving. The central question they addressed was whether changing the effective price of donating (i.e., increasing the impact of each donated dollar through matches) could influence individual giving behavior.\nThe study involved over 50,000 previous donors to a politically liberal nonprofit organization in the United States. Each donor received one of several versions of a fundraising letter via direct mail, a standard solicitation method used by the organization. The letters were identical in content—discussing an urgent national political issue—but varied in a few critical ways depending on the assigned experimental treatment.\nParticipants were randomly assigned to either:\n\nA control group that received a standard letter with no mention of a matching grant, or\nA treatment group that was informed of a matching offer funded by an anonymous donor.\n\nWithin the treatment group, further randomization occurred along three dimensions:\n\nMatch Ratio – Donors were told their contribution would be matched at a rate of $1:$1, $2:$1, or $3:$1.\nMaximum Match Size – The total matching fund was framed as being capped at $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amount – The solicitation letter used a donor-specific “example donation” set to be equal to, 1.25x, or 1.5x the donor’s highest previous contribution.\n\nThis design allowed the researchers to isolate not only the average effect of announcing a match but also to examine how donation behavior varied based on the size of the match ratio, the framing of the funding cap, and the suggested donation amount.\nThe results were both straightforward and surprising:\n\nAnnouncing the availability of a matching grant increased both response rate and total donations.\nHowever, increasing the match ratio beyond 1:1 did not produce additional gains—suggesting that donors responded to the presence of a match rather than its magnitude.\nInterestingly, the effect of the match offer was substantially stronger in red states (those that voted for Bush in 2004), suggesting political environment influences donor sensitivity.\n\nThis experiment not only contributed empirical evidence to the economics of charity—specifically the “demand side”—but also served as a real-world test of economic and behavioral theories such as impure altruism, warm-glow giving, and conditional cooperation. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#data",
    "href": "blog/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nBefore analyzing the effect of matching grants on donation behavior, we first verify whether the treatment and control groups are balanced on pre-treatment variables, as expected under random assignment. This is an important diagnostic step and is the purpose of Table 1 in the original paper by Karlan & List (2007).\nTo do this, we test whether certain pre-treatment characteristics are statistically different between groups using both:\n\nA two-sample t-test (per class slide formula)\nA linear regression, regressing the variable on the treatment dummy\n\nWe show this for two variables:\n\nmrm2: months since last donation\nyears: years since first donation\n\n\nVariable 1: mrm2 – Months Since Last Donation\nT-Test Formula Used:\n\\[\nt = \\frac{\\bar{X}_{\\text{treat}} - \\bar{X}_{\\text{control}}}{\\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}}\n\\]\nResults:\n\nt-statistic: 0.120\np-value: 0.905\nRegression coefficient: 0.014\nRegression p-value: 0.905\n\nInterpretation:\nThere is no significant difference in mrm2 between treatment and control. This confirms random assignment worked well for this variable.\ndf_clean = df[[\"treatment\", \"mrm2\"]].dropna()\ngroup_t = df_clean[df_clean[\"treatment\"] == 1][\"mrm2\"]\ngroup_c = df_clean[df_clean[\"treatment\"] == 0][\"mrm2\"]\n\n# Compute stats\nx1, x2 = group_t.mean(), group_c.mean()\ns1, s2 = group_t.std(ddof=1), group_c.std(ddof=1)\nn1, n2 = group_t.count(), group_c.count()\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_denom = ((s1**2 / n1 + s2**2 / n2)**2) / (((s1**2 / n1)**2) / (n1-1) + ((s2**2 / n2)**2) / (n2-1))\np_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_denom))\nmodel = smf.ols(\"mrm2 ~ treatment\", data=df_clean).fit()\nprint(model.summary().tables[1])\n\n\nVariable 2: years – Years Since First Donation\n\n\nResults:\n\nt-statistic: –1.091\np-value: 0.275\nRegression coefficient: –0.058\nRegression p-value: 0.270\n\nInterpretation:\nNo statistically significant difference here either. This supports the claim that treatment was randomized effectively.\ndf_clean2 = df[[\"treatment\", \"years\"]].dropna()\ngroup_t2 = df_clean2[df_clean2[\"treatment\"] == 1][\"years\"]\ngroup_c2 = df_clean2[df_clean2[\"treatment\"] == 0][\"years\"]\n\n# Compute stats\nx1, x2 = group_t2.mean(), group_c2.mean()\ns1, s2 = group_t2.std(ddof=1), group_c2.std(ddof=1)\nn1, n2 = group_t2.count(), group_c2.count()\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_denom = ((s1**2 / n1 + s2**2 / n2)**2) / (((s1**2 / n1)**2) / (n1-1) + ((s2**2 / n2)**2) / (n2-1))\np_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_denom))\nmodel = smf.ols(\"years ~ treatment\", data=df_clean2).fit()\nprint(model.summary().tables[1])\n\n\nVariable 3: female – Donor Gender Indicator\n\n\nResults:\nT-Test:\n\nt-statistic: –1.754\np-value: 0.080\n\n\n\nRegression coefficient: –0.0075\nRegression p-value: 0.079\n\nInterpretation:\n\nThe treatment group has a slightly lower proportion of female donors than the control group.\nHowever, this difference is not statistically significant at the 95% level (though it’s close — borderline at 10%).\nThis is still generally acceptable for a randomized design, but it’s good to note.\n\ndf_clean3 = df[[\"treatment\", \"female\"]].dropna()\ngroup_t3 = df_clean3[df_clean3[\"treatment\"] == 1][\"female\"]\ngroup_c3 = df_clean3[df_clean3[\"treatment\"] == 0][\"female\"]\n\nx1, x2 = group_t3.mean(), group_c3.mean()\ns1, s2 = group_t3.std(ddof=1), group_c3.std(ddof=1)\nn1, n2 = group_t3.count(), group_c3.count()\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_denom = ((s1**2 / n1 + s2**2 / n2)**2) / (((s1**2 / n1)**2) / (n1-1) + ((s2**2 / n2)**2) / (n2-1))\np_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_denom))\nmodel = smf.ols(\"female ~ treatment\", data=df_clean3).fit()\nmodel.summary()\n\n\nWhy This Matters\nTable 1 in Karlan & List (2007) exists to show that randomization created balance between the treatment and control groups. Our replication confirms that conclusion for mrm2, years, and female — giving us confidence that observed differences in donation behavior are not driven by pre-existing differences between groups."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#experimental-results",
    "href": "blog/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nBarplot: Donation Rates by Group\n\nThe plot shows a higher donation rate in the treatment group compared to the control group. This supports the hypothesis that mentioning a matching grant increases the likelihood of donation.\n\n\nT-Test Results\nUsing the class slide formula:\n\\[\nt = \\frac{\\bar{X}_{\\text{treat}} - \\bar{X}_{\\text{control}}}{\\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}}\n\\]\n\nt-statistic: 3.209\np-value: 0.0013 ✅ statistically significant\n\nThis tells us that the treatment and control groups differ meaningfully in donation behavior.\n\n\nBivariate Linear Regression\nWe regress gave (binary donation indicator) on treatment:\n\nTreatment coefficient: 0.00418\np-value: 0.0019 ✅ statistically significant\n\nThis means that being in the treatment group increased the donation rate by 0.4 percentage points — a nearly 22% increase over the baseline control group donation rate of ~1.8%.\nlm_g = smf.ols(\"gave ~ treatment\", data=df).fit()\nlm_g.summary()\n\n\n\nProbit Regression\nTo replicate Table 3, Column 1 in Karlan & List (2007), we run a probit model:\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprobit_model.summary()\n\nCoefficient on treatment: 0.0868\np-value: 0.0019 ✅ statistically significant\n\nThis matches the result in Table 3, Column 1 of the paper. A positive coefficient in the probit model reinforces the same conclusion: people respond positively to the presence of a matching grant.\n\nInterpretation\nThese results show that just knowing a donation will be matched makes people more likely to give. This supports theories in behavioral economics like impure altruism or “warm-glow giving” — where people care not just about helping, but about feeling effective when doing so.\nThe findings also reinforce why framing and context matter in fundraising. Small interventions like matching grants can produce significant shifts in behavior.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe conduct two pairwise t-tests:\n\n2:1 vs 1:1\n\nResponse Rate (2:1): 2.26%\nResponse Rate (1:1): 2.07%\nDifference: 0.19 percentage points\n\n3:1 vs 2:1\n\nResponse Rate (3:1): 2.27%\nResponse Rate (2:1): 2.26%\nDifference: ~0.01 percentage points\n\n\nConclusion: These results support what the authors of the paper describe: “figures suggest that larger match ratios do not substantially alter behavior.” The differences are numerically small and, as we’ll see below, not statistically significant.\n\nRegression: gave ~ ratio2 + ratio3\nWe use 1:1 as the baseline and include indicator variables for $2:$1 and $3:$1 matches.\nRegression Coefficients: - ratio2 (2:1 vs 1:1): +0.00188 (0.19 pp increase) - ratio3 (3:1 vs 1:1): +0.00198 (0.20 pp increase)\nreg_ratio_clean = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_ratio).fit()\nreg_ratio_clean.summary()\nInterpretation:\n\nThe coefficient estimates are consistent with the direct differences in donation rates.\nHowever, these increases are very small in absolute terms and not statistically significant (p-values &gt; 0.05).\nThis again supports the paper’s main claim: offering a match increases giving, but increasing the match ratio beyond $1:$1 does not lead to meaningful gains.\n\n\n\nSummary Table\n\n\n\nMatch Ratio\nDonation Rate\nDifference (vs prior)\n\n\n\n\n1:1\n2.07%\n—\n\n\n2:1\n2.26%\n+0.19 pp\n\n\n3:1\n2.27%\n+0.01 pp\n\n\n\n\n\nBehavioral Insight\nThese results suggest that the presence of a match, not its size, is what matters. Donors may interpret any match as a social signal or incentive to act, but they don’t seem to value a 3x match more than a 1x match.\nThis is consistent with behavioral theories like: - Warm-glow giving - Saturation effects in motivation - Signaling models of generosity\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#simulation-experiment",
    "href": "blog/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "this is my website",
    "section": "",
    "text": "this is my website"
  }
]