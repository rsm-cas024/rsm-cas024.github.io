[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "this is project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nCarolyn Su\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Unstructured Data\n\n\n\n\n\n\n\n\n\nApr 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project 1/index.html",
    "href": "blog/project 1/index.html",
    "title": "Analyzing Unstructured Data",
    "section": "",
    "text": "Gathered Formula 1 data from Year 2000 to Year 2024 and cleaned the data"
  },
  {
    "objectID": "blog/project 1/index.html#section-1-data",
    "href": "blog/project 1/index.html#section-1-data",
    "title": "Analyzing Unstructured Data",
    "section": "",
    "text": "Gathered Formula 1 data from Year 2000 to Year 2024 and cleaned the data"
  },
  {
    "objectID": "blog/project 1/index.html#section-2-train-xgboost-model",
    "href": "blog/project 1/index.html#section-2-train-xgboost-model",
    "title": "Analyzing Unstructured Data",
    "section": "Section 2: Train XGBoost Model",
    "text": "Section 2: Train XGBoost Model\nUsed historical data to train an XGBoost Model\n\nimport numpy as np\nprint('123')\n\n123"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carolyn Su",
    "section": "",
    "text": "Hi there!\nMy name is Carolyn and I am an MSBA student at UC San Diego."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html",
    "href": "blog/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 paper published in The American Economic Review, economists Dean Karlan and John List conducted a large-scale natural field experiment to explore the effect of matching grants on charitable giving. The central question they addressed was whether changing the effective price of donating (i.e., increasing the impact of each donated dollar through matches) could influence individual giving behavior.\nThe study involved over 50,000 previous donors to a politically liberal nonprofit organization in the United States. Each donor received one of several versions of a fundraising letter via direct mail, a standard solicitation method used by the organization. The letters were identical in content—discussing an urgent national political issue—but varied in a few critical ways depending on the assigned experimental treatment.\nParticipants were randomly assigned to either:\n\nA control group that received a standard letter with no mention of a matching grant, or\nA treatment group that was informed of a matching offer funded by an anonymous donor.\n\nWithin the treatment group, further randomization occurred along three dimensions:\n\nMatch Ratio – Donors were told their contribution would be matched at a rate of 1:1, 2:1, or 3:1.\nMaximum Match Size – The total matching fund was framed as being capped at $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amount – The solicitation letter used a donor-specific “example donation” set to be equal to, 1.25x, or 1.5x the donor’s highest previous contribution.\n\nThis design allowed the researchers to isolate not only the average effect of announcing a match but also to examine how donation behavior varied based on the size of the match ratio, the framing of the funding cap, and the suggested donation amount.\nThe results were both straightforward and surprising:\n\nAnnouncing the availability of a matching grant increased both response rate and total donations.\nHowever, increasing the match ratio beyond 1:1 did not produce additional gains—suggesting that donors responded to the presence of a match rather than its magnitude.\nInterestingly, the effect of the match offer was substantially stronger in red states (those that voted for Bush in 2004), suggesting political environment influences donor sensitivity.\n\nThis experiment not only contributed empirical evidence to the economics of charity—specifically the “demand side”—but also served as a real-world test of economic and behavioral theories such as impure altruism, warm-glow giving, and conditional cooperation. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#introduction",
    "href": "blog/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 paper published in The American Economic Review, economists Dean Karlan and John List conducted a large-scale natural field experiment to explore the effect of matching grants on charitable giving. The central question they addressed was whether changing the effective price of donating (i.e., increasing the impact of each donated dollar through matches) could influence individual giving behavior.\nThe study involved over 50,000 previous donors to a politically liberal nonprofit organization in the United States. Each donor received one of several versions of a fundraising letter via direct mail, a standard solicitation method used by the organization. The letters were identical in content—discussing an urgent national political issue—but varied in a few critical ways depending on the assigned experimental treatment.\nParticipants were randomly assigned to either:\n\nA control group that received a standard letter with no mention of a matching grant, or\nA treatment group that was informed of a matching offer funded by an anonymous donor.\n\nWithin the treatment group, further randomization occurred along three dimensions:\n\nMatch Ratio – Donors were told their contribution would be matched at a rate of 1:1, 2:1, or 3:1.\nMaximum Match Size – The total matching fund was framed as being capped at $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amount – The solicitation letter used a donor-specific “example donation” set to be equal to, 1.25x, or 1.5x the donor’s highest previous contribution.\n\nThis design allowed the researchers to isolate not only the average effect of announcing a match but also to examine how donation behavior varied based on the size of the match ratio, the framing of the funding cap, and the suggested donation amount.\nThe results were both straightforward and surprising:\n\nAnnouncing the availability of a matching grant increased both response rate and total donations.\nHowever, increasing the match ratio beyond 1:1 did not produce additional gains—suggesting that donors responded to the presence of a match rather than its magnitude.\nInterestingly, the effect of the match offer was substantially stronger in red states (those that voted for Bush in 2004), suggesting political environment influences donor sensitivity.\n\nThis experiment not only contributed empirical evidence to the economics of charity—specifically the “demand side”—but also served as a real-world test of economic and behavioral theories such as impure altruism, warm-glow giving, and conditional cooperation. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#data",
    "href": "blog/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nBefore analyzing the effect of matching grants on donation behavior, we first verify whether the treatment and control groups are balanced on pre-treatment variables, as expected under random assignment. This is an important diagnostic step and is the purpose of Table 1 in the original paper by Karlan & List (2007).\nTo do this, we test whether certain pre-treatment characteristics are statistically different between groups using both:\n\nA two-sample t-test (per class slide formula)\nA linear regression, regressing the variable on the treatment dummy\n\nWe show this for two variables:\n\nmrm2: months since last donation\nyears: years since first donation\n\n\nVariable 1: mrm2 – Months Since Last Donation\nT-Test Formula Used:\n\\[\nt = \\frac{\\bar{X}_{\\text{treat}} - \\bar{X}_{\\text{control}}}{\\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}}\n\\]\nResults:\n\nt-statistic: 0.120\np-value: 0.905\nRegression coefficient: 0.014\nRegression p-value: 0.905\n\nInterpretation:\nThere is no significant difference in mrm2 between treatment and control. This confirms random assignment worked well for this variable.\n\n# Import libraries\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Clean data: drop rows with missing 'mrm2'\ndf_clean = df[[\"treatment\", \"mrm2\"]].dropna()\n\n# Split into treatment and control groups\ngroup_t = df_clean[df_clean[\"treatment\"] == 1][\"mrm2\"]\ngroup_c = df_clean[df_clean[\"treatment\"] == 0][\"mrm2\"]\n\n# Compute group stats\nx1, x2 = group_t.mean(), group_c.mean()\ns1, s2 = group_t.std(ddof=1), group_c.std(ddof=1)\nn1, n2 = group_t.count(), group_c.count()\n\n# Calculate standard error and t-stat using the class formula\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\n\n# Degrees of freedom using Welch–Satterthwaite approximation\ndf_denom = ((s1**2 / n1 + s2**2 / n2) ** 2) / (((s1**2 / n1) ** 2) / (n1 - 1) + ((s2**2 / n2) ** 2) / (n2 - 1))\n\n# Two-tailed p-value\np_val_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_denom))\n\nprint(\"T-test result\")\nprint(f\"  t-statistic: {t_stat:.3f}\")\nprint(f\"  p-value: {p_val_ttest:.3f}\")\n\nT-test result\n  t-statistic: 0.120\n  p-value: 0.905\n\n\n\n# Now perform the equivalent linear regression\nmodel = smf.ols(\"mrm2 ~ treatment\", data=df_clean).fit()\nprint(\"Linear regression result\")\nprint(model.summary().tables[1])\n\nLinear regression result\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\n\n\n\n\nVariable 2: years – Years Since First Donation\n\n\nResults:\n\nt-statistic: –1.091\np-value: 0.275\nRegression coefficient: –0.058\nRegression p-value: 0.270\n\nInterpretation:\nNo statistically significant difference here either. This supports the claim that treatment was randomized effectively.\n\ndf_clean2 = df[[\"treatment\", \"years\"]].dropna()\ngroup_t2 = df_clean2[df_clean2[\"treatment\"] == 1][\"years\"]\ngroup_c2 = df_clean2[df_clean2[\"treatment\"] == 0][\"years\"]\n\n# Compute stats\nx1, x2 = group_t2.mean(), group_c2.mean()\ns1, s2 = group_t2.std(ddof=1), group_c2.std(ddof=1)\nn1, n2 = group_t2.count(), group_c2.count()\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_denom = ((s1**2 / n1 + s2**2 / n2)**2) / (((s1**2 / n1)**2) / (n1-1) + ((s2**2 / n2)**2) / (n2-1))\np_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_denom))\n\n\nmodel = smf.ols(\"years ~ treatment\", data=df_clean2).fit()\nprint(model.summary().tables[1])\n\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      6.1359      0.043    144.023      0.000       6.052       6.219\ntreatment     -0.0575      0.052     -1.103      0.270      -0.160       0.045\n==============================================================================\n\n\n\n\nVariable 3: female – Donor Gender Indicator\n\n\nResults:\nT-Test:\n\nt-statistic: –1.754\np-value: 0.080\nRegression coefficient: –0.0075\nRegression p-value: 0.079\n\nInterpretation:\n\nThe treatment group has a slightly lower proportion of female donors than the control group.\nHowever, this difference is not statistically significant at the 95% level (though it’s close — borderline at 10%).\nThis is still generally acceptable for a randomized design, but it’s good to note.\n\n\ndf_clean3 = df[[\"treatment\", \"female\"]].dropna()\ngroup_t3 = df_clean3[df_clean3[\"treatment\"] == 1][\"female\"]\ngroup_c3 = df_clean3[df_clean3[\"treatment\"] == 0][\"female\"]\n\nx1, x2 = group_t3.mean(), group_c3.mean()\ns1, s2 = group_t3.std(ddof=1), group_c3.std(ddof=1)\nn1, n2 = group_t3.count(), group_c3.count()\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_denom = ((s1**2 / n1 + s2**2 / n2)**2) / (((s1**2 / n1)**2) / (n1-1) + ((s2**2 / n2)**2) / (n2-1))\np_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_denom))\n\n\nmodel = smf.ols(\"female ~ treatment\", data=df_clean3).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nfemale\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n3.092\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.0787\n\n\nTime:\n21:02:39\nLog-Likelihood:\n-30148.\n\n\nNo. Observations:\n48972\nAIC:\n6.030e+04\n\n\nDf Residuals:\n48970\nBIC:\n6.032e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.2827\n0.004\n80.688\n0.000\n0.276\n0.290\n\n\ntreatment\n-0.0075\n0.004\n-1.758\n0.079\n-0.016\n0.001\n\n\n\n\n\n\n\n\nOmnibus:\n17873.494\nDurbin-Watson:\n2.004\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n10142.985\n\n\nSkew:\n0.993\nProb(JB):\n0.00\n\n\nKurtosis:\n1.986\nCond. No.\n3.22\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nConclusion\nTable 1 in Karlan & List (2007) exists to show that randomization created balance between the treatment and control groups. Our replication confirms that conclusion for mrm2, years, and female — giving us confidence that observed differences in donation behavior are not driven by pre-existing differences between groups."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#experimental-results",
    "href": "blog/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nBarplot: Donation Rates by Group\n\nThe plot shows a higher donation rate in the treatment group compared to the control group. This supports the hypothesis that mentioning a matching grant increases the likelihood of donation.\n\n\nT-Test Results\nUsing the class slide formula:\n\\[\nt = \\frac{\\bar{X}_{\\text{treat}} - \\bar{X}_{\\text{control}}}{\\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}}\n\\]\n\nt-statistic: 3.209\np-value: 0.0013\n\nThis tells us that the treatment and control groups differ meaningfully in donation behavior.\n\n\nBivariate Linear Regression\nWe regress gave (binary donation indicator) on treatment:\n\nTreatment coefficient: 0.00418\np-value: 0.0019\n\nThis means that being in the treatment group increased the donation rate by 0.4 percentage points — a nearly 22% increase over the baseline control group donation rate of ~1.8%.\n\nlm_g = smf.ols(\"gave ~ treatment\", data=df).fit()\nlm_g.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n9.618\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.00193\n\n\nTime:\n21:02:39\nLog-Likelihood:\n26630.\n\n\nNo. Observations:\n50083\nAIC:\n-5.326e+04\n\n\nDf Residuals:\n50081\nBIC:\n-5.324e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0179\n0.001\n16.225\n0.000\n0.016\n0.020\n\n\ntreatment\n0.0042\n0.001\n3.101\n0.002\n0.002\n0.007\n\n\n\n\n\n\n\n\nOmnibus:\n59814.280\nDurbin-Watson:\n2.005\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n4317152.727\n\n\nSkew:\n6.740\nProb(JB):\n0.00\n\n\nKurtosis:\n46.440\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nProbit Regression\nTo replicate Table 3, Column 1 in Karlan & List (2007), we run a probit model:\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprobit_model.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nWed, 23 Apr 2025\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n21:02:39\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n\nCoefficient on treatment: 0.0868\np-value: 0.0019\n\nThis matches the result in Table 3, Column 1 of the paper. A positive coefficient in the probit model reinforces the same conclusion: people respond positively to the presence of a matching grant.\n\nInterpretation\nThese results show that just knowing a donation will be matched makes people more likely to give. This supports theories in behavioral economics like impure altruism or “warm-glow giving” — where people care not just about helping, but about feeling effective when doing so.\nThe findings also reinforce why framing and context matter in fundraising. Small interventions like matching grants can produce significant shifts in behavior.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe conduct two pairwise t-tests:\n\n2:1 vs 1:1\n\nResponse Rate (2:1): 2.26%\nResponse Rate (1:1): 2.07%\nDifference: 0.19 percentage points\n\n3:1 vs 2:1\n\nResponse Rate (3:1): 2.27%\nResponse Rate (2:1): 2.26%\nDifference: ~0.01 percentage points\n\n\nThese results support what the authors of the paper describe: “figures suggest that larger match ratios do not substantially alter behavior.” The differences are numerically small and, as we’ll see below, not statistically significant.\n\nRegression: gave ~ ratio2 + ratio3\nWe use 1:1 as the baseline and include indicator variables for 2:1 and 3:1 matches.\nRegression Coefficients:\n\nratio2 (2:1 vs 1:1): +0.00188 (0.19 pp increase)\nratio3 (3:1 vs 1:1): +0.00198 (0.20 pp increase)\n\n\ndf_ratio = df[(df[\"treatment\"] == 1) & (df[\"ratio\"].isin([1, 2, 3]))][[\"gave\", \"ratio\"]].dropna()\n\ndf_ratio[\"ratio2\"] = (df_ratio[\"ratio\"] == 2).astype(int)\ndf_ratio[\"ratio3\"] = (df_ratio[\"ratio\"] == 3).astype(int)\n\nreg_ratio_clean = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_ratio).fit()\nreg_ratio_clean.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n21:02:39\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0019\n0.002\n0.958\n0.338\n-0.002\n0.006\n\n\nratio3\n0.0020\n0.002\n1.008\n0.313\n-0.002\n0.006\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nInterpretation:\n\nThe coefficient estimates are consistent with the direct differences in donation rates.\nHowever, these increases are very small in absolute terms and not statistically significant (p-values &gt; 0.05).\nThis again supports the paper’s main claim: offering a match increases giving, but increasing the match ratio beyond $1:$1 does not lead to meaningful gains.\n\n\n\nSummary Table\n\n\n\nMatch Ratio\nDonation Rate\nDifference (vs prior)\n\n\n\n\n1:1\n2.07%\n—\n\n\n2:1\n2.26%\n+0.19 pp\n\n\n3:1\n2.27%\n+0.01 pp\n\n\n\n\n\nBehavioral Insight\nThese results suggest that the presence of a match, not its size, is what matters. Donors may interpret any match as a social signal or incentive to act, but they don’t seem to value a 3x match more than a 1x match.\nThis is consistent with behavioral theories like: - Warm-glow giving - Saturation effects in motivation - Signaling models of generosity\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nWe first run a regression on the full sample, including both donors and non-donors:\n\ndf_amt_full = df[[\"treatment\", \"amount\"]].dropna()\nlm_amt_full = smf.ols(\"amount ~ treatment\", data=df_amt_full).fit()\n\nResult:\n\nTreatment coefficient: 0.15\np-value: 0.063\n\nThis result suggests that people in the treatment group gave 15 cents more on average than those in the control group. It is marginally statistically significant at the 10% level, but not at 5%. So, while the match offer might increase total revenue slightly, the effect is modest.\nWe now repeat the analysis using only donors (those with amount &gt; 0):\n\ndf_amt_positive = df[df[\"amount\"] &gt; 0]\nlm_amt_donors = smf.ols(\"amount ~ treatment\", data=df_amt_positive).fit()\n\nResult:\n\nTreatment coefficient: –1.67\np-value: 0.561\n\nOnce we condition on having donated, there is no significant difference in how much people in the treatment vs. control groups gave. In fact, the point estimate is negative — donors in the treatment group gave slightly less, but this difference is small and statistically insignificant.\nInterpretation\nThe first regression (full sample) has a causal interpretation due to random assignment. It tells us the effect of treatment on average giving across everyone.\nThe second regression (among donors) does not have a clear causal interpretation — the group of people who chose to donate may differ between treatment and control.\nThe following plots show the distribution of donation amounts among people who gave, separated by group. A red dashed line marks the average in each group.\n\nThese plots show that:\n\nThe donation distribution is heavily right-skewed in both groups.\nThe mean is slightly higher in the control group, supporting the regression result among donors.\n\n\nConclusion\n\nOffering a match increases the likelihood that someone gives, but does not meaningfully affect the size of the donation among those who already chose to give.\nThis aligns with theories of warm-glow giving and threshold effects — people may be triggered to act, but their internal sense of how much to give remains stable."
  },
  {
    "objectID": "blog/HW1/hw1_questions.html#simulation-experiment",
    "href": "blog/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nWe assume:\n\nThe control group follows a Bernoulli distribution with \\(p = 0.018\\)\nThe treatment group follows a Bernoulli distribution with \\(p = 0.022\\)\n\nThe true difference in donation rates is therefore \\(0.022 - 0.018 = 0.004\\).\n\n\nSimulation Setup\nWe simulate:\n\n100,000 donation responses from the control distribution.\n10,000 donation responses from the treatment distribution.\nFrom these, we compute a vector of 10,000 differences in donation outcomes between treatment and randomly sampled control units.\n\nWe then plot the cumulative average of those 10,000 differences.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# True probabilities\np_control = 0.018\np_treatment = 0.022\n\n# Simulation sizes\nn_control = 100000\nn_treatment = 10000\n\n# Simulate donation outcomes\nsim_control = np.random.binomial(1, p_control, n_control)\nsim_treatment = np.random.binomial(1, p_treatment, n_treatment)\n\n# Random sample from control to match treatment size\nsim_control_sampled = np.random.choice(sim_control, size=n_treatment, replace=False)\n\n# Calculate differences and cumulative average\ndiffs = sim_treatment - sim_control_sampled\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg. of Differences\")\nplt.axhline(p_treatment - p_control, color='red', linestyle='--', label='True Mean Difference (0.004)')\nplt.title(\"Cumulative Average of Differences (Treatment - Control)\")\nplt.xlabel(\"Simulation Index\")\nplt.ylabel(\"Cumulative Average\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretation\nThe blue line shows the cumulative average difference between simulated treatment and control groups. As more simulations accumulate, the cumulative average converges to the true difference of 0.004, shown with a red dashed line.\nThis visually demonstrates the Law of Large Numbers — as sample size grows, the sample average converges to the true population mean.\n\n\n\nCentral Limit Theorem\nTo demonstrate the Central Limit Theorem (CLT), we simulate repeated sampling from control and treatment groups with known probabilities of donation:\n\nControl group: Bernoulli with \\(p = 0.018\\)\nTreatment group: Bernoulli with \\(p = 0.022\\) - True difference = \\(0.004\\)\n\nWe draw samples of size 50, 200, 500, and 1000, and repeat each sampling process 1,000 times. For each repetition, we calculate the average difference in donation rate between treatment and control samples.\n\nSimulating the Sampling Distribution\n\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nsimulations = 1000\nsample_sizes = [50, 200, 500, 1000]\ndiff_distributions = {}\n\nfor n in sample_sizes:\n    avg_diffs = []\n    for _ in range(simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        avg_diffs.append(treatment_sample.mean() - control_sample.mean())\n    diff_distributions[n] = avg_diffs\n\n\n\nPlotting the Results\n\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 8))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    axs[i].hist(diff_distributions[n], bins=30, alpha=0.7)\n    axs[i].axvline(0, color='red', linestyle='--', label=\"Zero\")\n    axs[i].axvline(0.004, color='green', linestyle='--', label=\"True Diff (0.004)\")\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Avg. Difference (p̂_treat - p̂_control)\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Sampling Distribution of Differences: Central Limit Theorem\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nEach histogram shows the distribution of 1,000 simulated average differences between treatment and control outcomes at different sample sizes.\n\nWhen \\(n = 50\\), the distribution is noisy and spread out, with zero not obviously in the center.\nAs sample size increases, the distribution becomes more normal-shaped and tightly centered around the true difference of 0.004.\nBy \\(n = 1000\\), the sampling distribution is narrow and well-separated from zero, showing how larger sample sizes improve precision.\n\nThis is the Central Limit Theorem in action: the average of many independent samples approximates a normal distribution, even when the underlying variable (donation or not) is binary."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "this is my website",
    "section": "",
    "text": "this is my website"
  }
]